%===================================================================================
% Chapter: Dataset
%===================================================================================
\chapter{Análisis del conjunto de datos}\label{chapter:dataset}
% \addcontentsline{toc}{chapter}{Análisis del conjunto de datos}
%===================================================================================

En el proceso de entrenamiento y prueba de los algoritmos de aprendizaje de máquina, el conjunto de datos utilizado es de gran importancia, pero escoger uno lo suficientemente bueno no es tarea fácil. El conjunto KDDCup99 fue elaborado por el MIT Lincoln Lab patrocinado por DARPA en un escenario simulado donde realizaban ataques a la base de las fuerzas aéreas, lo cual tuvo una duración de 9 semanas [referencias]. Los datos fueron analizados y separados según el tipo de ataque o tráfico no malicioso de la red. Es uno de los conjuntos públicos disponibles que contiene ataques actuales y más utilizados para la construcción de IDS, lo que facilita la comparación de diferentes trabajos.

\section{Descripción del conjunto de datos}\label{section:dataset_description}
El conjunto de datos KDDCup99 posee aproximadamente 5 millones de datos los que se dividen en 5 clases:

\begin{itemize}
    \item Normal: tráfico común que navega por la red como puede ser el acceso a un sitio web o el envío de archivos no maliciosos.
    \item Negación de Servicios (DoS): esto es un ataque que ocupa gran parte del poder de cómputo o la memoria haciendo así que otras peticiones no puedan ser atendidas.
    \item Probing: un atacante escanea la red para ganar información que pueda explotar en el momento de infiltrarse en esta.
    \item Ataque remoto a un equipo local (R2L): el atacante envía paquetes a la red con el objetivo de explotar alguna vulnerabilidad disponible y ganar acceso local.
    \item User to Root (U2R): el atacante accede a la red desde una cuenta de usuario común y explota las vulnerabilidades existentes para ganar acceso como administrador en el sistema.
\end{itemize}

De igual forma, cada paquete contiene 41 características que pueden ser continuas o discretas. Estas están divididas en 4 categorías:

\begin{itemize}
    \item Características básicas que están derivadas de los encabezados de los paquetes sin inspeccionar los datos transmitidos.
    \item Características de contenido para los cuales se utiliza el conocimiento del dominio para evaluar la carga útil de los paquetes TCP originales.
    \item Características basadas en el tiempo de tráfico.
    \item Características basadas en el tráfico del host.
\end{itemize}

Este conjunto de datos tiene algunos problemas como el contenido de datos redundantes causando que los algoritmos de aprendizaje tengan una inclinación por los datos más frecuentes, el número de entradas para elaborar un conjunto de test puede variar en cada trabajo dado que el conjunto de datos no está separado, entre otros. Para eliminar algunos de estos errores se elaboró el conjunto NSL-KDD con un total de 1.1 millones de datos. A pesar de los esfuerzos, este aún sufre de algunos problemas tratados por McHugh \cite{mchugh2000testing} y no es una representación perfecta del contenido real en las redes. Por la falta de conjuntos de datos públicos, este puede ser un buen medidor para ayudar a las diferentes investigaciones y poderlas comparar entre sí. 

En adición, cada dato contiene un nivel de dificultad. Para lograr este objetivo se entrenaron 7 algoritmos diferentes, cada uno 3 veces, y a cada dato que aceptaron se le incrementó en uno el valor de dificultad, siendo 21 el valor máximo representando el nivel de dificultad más bajo. El conjunto de datos en su totalidad consta de 8 archivos:

\begin{itemize}
    \item KDDTrain+.arff : el conjunto de entrenamiento completo con los datos clasificados en normal y anómalos.
    \item KDDTrain+.txt : el conjunto de entrenamiento completo con los datos clasificados según el tipo de ataque y el nivel de dificultad.
    \item KDDTrain+\_20Percent.arff : subconjunto de 20\% del archivo KDDTrain+.arff.
    \item KDDTrain+\_20Percent.txt : subconjunto de 20\% del archivo KDDTrain+.txt.
    \item KDDTest+.arff : conjunto de prueba completo con los datos clasificados en normal y anómalos. Posee datos diferentes y algunas clasificaciones de ataques nuevas con respecto al conjunto de entrenamiento.
    \item KDDTest+.txt : conjunto de prueba completo con los datos clasificados según el tipo de ataque y el nivel de dificultad. Posee datos diferentes y algunas clasificaciones de ataques nuevas con respecto al conjunto de entrenamiento.
    \item KDDTest-21.arff : subconjunto de KDDTest+.arff que no contiene los datos con dificultad 21 de 21.
    \item KDDTest-21.txt : subconjunto de KDDTest+.txt que no contiene los datos con dificultad 21 de 21.
\end{itemize}

\section{Pre procesamiento de los datos}
Con el objetivo de optimizar el proceso de aprendizaje y los resultados obtenidos por los algoritmos es necesario realizar un pre procesamiento de los datos. Este consiste en la transformación y normalización de los datos dado que existen campos con valores reales y otros con dominio definido. Para los campos con valores binarios reales no es necesario realizar ninguna transformación [referenciar].

Los campos con valores reales tienen como valor mínimo el 0 por lo que el proceso de normalización consiste en buscar el valor máximo de cada campo y dividir todos los valores por este. En el caso de los campos con dominio definido, como lo es protocol\_type que sus valores pertenecen al dominio \{'tcp', 'udp', 'icmp'\}, se le asigna un valor entero a cada posible valor, igual al su indice en la lista de posibles valores, y luego se dividen entre el máximo valor que es igual a la cantidad de valores posibles menos uno. Después de estos procesos todos los campos de los datos poseen valores entre 0 y 1.

\section{Selección de variables}
Los mecanismos de selección de variables ayudan a identificar y remover las no esenciales, irrelevantes y redundantes de los datos que no influyen en la precisión de los resultados. La selección de variables es el proceso que indica cual es la mejor representación de los datos para resolver un problema determinado. Si este proceso no se aplica, puede tener un efecto negativo en la precisión de las respuestas de los modelos de predicción [referenciar].

Uno de los métodos más utilizados para lograr este objetivo es el de bosques aleatorios. Este clasificador ha brindado buenos resultados para el problema en cuestión. Es un algoritmo basado en árboles que se utiliza en problemas de clasificación y ayuda a obtener la importancia de las características en cada uno. Se puso a prueba en el conjunto NSL-KDD y de un total de 41 características se descartaron 11 que aportaban poca información sobre la clasificación de los datos, quedando así 30 para el entrenamiento de los algoritmos clasificadores.

\section{Clasificación}
\begin{table}[b]
    \begin{center}
        \caption{Asociación de los tipos de ataques a sus categorías.}
        
        \label{tab:class}
        \begin{tabular}{l|l} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
        \textbf{Categorías} & \textbf{Tipos de ataques}\\
        \hline
        DoS & back, land, neptune, pod, smurf, teardrop, mailbomb,\\ 
        & apache2, processtable, udpstorm\\
        Probe & ipsweep, nmap, portsweep, satan, mscan, saint\\
        R2L & ftp write, guess passwd, imap, multihop, phf, spy,\\
        & warezclient, warezmaster, sendmail, named,\\
        & snmpgetattack, snmpguess, xlock, xsnoop, worm\\
        U2R & buffer overflow, loadmodule, perl, rootkit, httptunnel,\\
        & ps, sqlattack, xterm\\
        \end{tabular}
    \end{center}
\end{table}

La clasificación es el proceso de predicción de los datos luego de que el algoritmo seleccionado sea entrenado. En el caso de este conjunto de datos específico las entradas poseen varias clases. Como se mencionó con anterioridad este trabajo se centra solo en la clasificación binaria, debido a que en la práctica es más importante la detección de un ataque que su clasificación. A pesar de esto, el conocimiento del tipo del ataque puede ayudar a una prevención mas adecuada. Las diferentes clases presentes en NSL-KDD se muestran en la tabla \ref{tab:class}.


A pesar de que este conjunto de datos tiene grandes virtudes, no es perfecto. Algo que lo perjudica son las cantidades de datos en cada una de las categorías de ataques. Como muestra la tabla \ref{tab:atk_counts} hay tipos de ataques que poseen una mayor cantidad de entradas lo cual puede causar una inclinación en los algoritmos de aprendizaje de máquina.

\begin{table}[h]
    \begin{center}
        \caption{Distribución de los datos en los subconjuntos de entrenamiento y prueba.}
        
        \label{tab:atk_counts}
        \begin{tabular}{c|c|c|c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
        \textbf{} & \textbf{Normal} & \textbf{DoS} & \textbf{Probe} & \textbf{U2R} & \textbf{R2L} & \textbf{Total}\\
        \hline
        \textbf{Train} & 67343 & 45927 & 11656 & 52 & 995 & 125973\\
        \textbf{Test} & 9711 & 7458 & 2421 & 200 & 2754 & 22543\\
        \end{tabular}
    \end{center}
\end{table}

\section{Experimentación}
Mostrar los parámetros seleccionados y porque se escogieron esos según alguna literatura.

\subsection{Análisis de reducción de dimensiones}
Para que es útil y como mejora los resultados. Comparación de algunos algoritmos, selección del mejor.
La selección de características en este campo es esencial, con las variables correctas se puede reducir el \textit{overfitting}, mejorar el desempeño de los algoritmos y tener un mejor entendimiento sobre los procesos que generaron los datos. Random forest (RF) es un algoritmo basado en arboles ampliamente utilizado para obtener un estimado de la importancia que tiene cada característica de los datos. Consiste en la construcción de un conjunto ensemble de M árboles de decisión especializados, cada uno entrenado en un subconjunto del total de datos, escogido de modo aleatorio con reemplazo \cite{hasan2016feature}.

\subsection{Conjunto de datos original}
Explicar el proceso que se realizó con el dataset sin modificar. Poner los resultados obtenidos con y sin k-fold.
El conjunto de datos NSL-KDD es ampliamente utilizado por investigadores en la elaboración de ids, parte de su popularidad se debe a las particiones que este ya posee. Este conjunto de datos posee un subconjunto de entrenamiento, con casos de ataques y otros de tráfico común, y uno de test, que de igual manera posee ataques y trafico normal, aunque en el caso de los ataques posee algunos tipos que no se encuentran en el conjunto de entrenamiento. Gracias a esto, diferentes algoritmos pueden ser comparados con un alto nivel de precisión.
Para una mayor precisión en los resultados se utilizó el método k-fold \cite{10.5555/3203489}. Este consiste en dividir el conjunto de entrenamiento en k particiones, creando k modelos idénticos y entrenando el i-esimo con las k-1 restantes mientras que se evalúan con la i-esima partición. Luego de obtener los k resultados se promedian. El valor de k escogido fue de 5 (usualmente se trabaja con 5 o 4) con 100 epochs y un tamaño de batch de 64. Al comienzo se desordenaron los datos del conjunto de entrenamiento de modo aleatorio.

\subsection{Conjunto de datos modificado}
Los altos valores de validación obtenidos anteriormente sugieren que el modelo está aprendiendo muy bien los datos que se encuentran en el conjunto de entrenamiento pero no está generalizando lo suficiente para obtener resultados similares en la fase de test. Por esta razón se decidió crear un nuevo conjunto de datos mezclando el de entrenamiento y el de test en uno solo, desordenarlo aleatoriamente, crear dos nuevas particiones de entrenamiento y test y con ellas entrenar. Con este proceso se garantiza una mejor distribución de los datos en la que los más complicados para el algoritmo pueden estar en el conjunto de entrenamiento, no solo en el de test.
Para este proceso se unieron los conjuntos de entrenamiento y de test en uno solo, se desordeno aleatoriamente y luego se tomaron el 80\% y el 20\% de los datos para la creación de los nuevos conjuntos de entrenamiento y de test respectivamente. Para obtener una mejor aproximación al resultado real, este proceso se realizó 5 veces y en cada una de ellas se entrenó y testeo el modelo.

Explicar cómo se realizó el nuevo conjunto de datos. Explicar el proceso de clasificación llevado a cabo y mostrar mejoras sobre el proceso anterior